#!/usr/bin/env python3
"""
MediaCrawler Skill åŒ…è£…è„šæœ¬
ä½¿ç”¨skillå†…ç½®çš„å®Œæ•´MediaCrawlerä»£ç åº“
"""

import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ skillæ ¹ç›®å½•åˆ°Pythonè·¯å¾„
skill_root = Path(__file__).parent.parent
sys.path.insert(0, str(skill_root))

# å¯¼å…¥é…ç½®å’Œçˆ¬è™«
import config
from media_platform.xhs import XiaoHongShuCrawler
from media_platform.douyin import DouYinCrawler
from media_platform.kuaishou import KuaishouCrawler
from media_platform.bilibili import BilibiliCrawler
from media_platform.weibo import WeiboCrawler


async def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='MediaCrawler Skill - å¤šå¹³å°åª’ä½“çˆ¬è™«')
    parser.add_argument('--platform', type=str, required=True, 
                       choices=['xhs', 'dy', 'ks', 'bili', 'wb'], 
                       help='ç›®æ ‡å¹³å° (xhs=å°çº¢ä¹¦, dy=æŠ–éŸ³, ks=å¿«æ‰‹, bili=Bç«™, wb=å¾®åš)')
    parser.add_argument('--keywords', type=str, required=True,
                       help='æœç´¢å…³é”®è¯ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”')
    parser.add_argument('--login-type', type=str, default='qrcode',
                       choices=['qrcode', 'cookie', 'phone'],
                       help='ç™»å½•æ–¹å¼')
    parser.add_argument('--cookies', type=str, default='',
                       help='Cookieå­—ç¬¦ä¸² (ç”¨äºcookieç™»å½•)')
    parser.add_argument('--headless', action='store_true',
                       help='æ— å¤´æ¨¡å¼è¿è¡Œ')
    parser.add_argument('--max-notes', type=int, default=20,
                       help='æœ€å¤§çˆ¬å–ç¬”è®°/è§†é¢‘æ•°é‡')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ¤– MediaCrawler Skill - å¤šå¹³å°åª’ä½“æ•°æ®çˆ¬è™«")
    print("=" * 60)
    print(f"ğŸ“ å¹³å°: {args.platform.upper()}")
    print(f"ğŸ” å…³é”®è¯: {args.keywords}")
    print(f"ğŸ” ç™»å½•æ–¹å¼: {args.login_type}")
    print(f"ğŸ–¥ï¸  æµè§ˆå™¨æ¨¡å¼: {'æ— å¤´' if args.headless else 'æœ‰å¤´'}")
    print(f"ğŸ“Š æœ€å¤§çˆ¬å–æ•°: {args.max_notes}")
    print("=" * 60)
    
    # åŠ¨æ€æ›´æ–°é…ç½®
    config.PLATFORM = args.platform
    config.KEYWORDS = args.keywords
    config.LOGIN_TYPE = args.login_type
    if args.cookies:
        config.COOKIES = args.cookies
    config.HEADLESS = args.headless
    config.CRAWLER_MAX_NOTES_COUNT = args.max_notes
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    crawler_map = {
        'xhs': XiaoHongShuCrawler,
        'dy': DouYinCrawler,
        'ks': KuaishouCrawler,
        'bili': BilibiliCrawler,
        'wb': WeiboCrawler
    }
    
    crawler_class = crawler_map.get(args.platform)
    if not crawler_class:
        print(f"âŒ ä¸æ”¯æŒçš„å¹³å°: {args.platform}")
        return 1
    
    try:
        crawler = crawler_class()
        print(f"\nğŸš€ å¼€å§‹çˆ¬å– {args.platform.upper()} å¹³å°å†…å®¹...")
        await crawler.start()
        print("\nâœ… çˆ¬å–ä»»åŠ¡å®Œæˆï¼")
        return 0
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 130
    except Exception as e:
        print(f"\nâŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
